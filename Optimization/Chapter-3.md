# Chapter 3

```ad-abstract
TODO
```

```ad-summary
Γενικός αλγόριθμος βελτιστοποίησης:

1. Επιλογή μίας αρχικής πρόβλεψης (ενός αρχικού διανύσματος) $x_0$
2. Για $k = 0, 1, \dots$
	1. Αν η $x_k$ ικανοποιεί μία συνθήκη βελτίστου τότε η προσεγγιστική τιμή του βελτιστοποιητή είναι η $x_k$
	2. Διαφορετικά, προσδιορίζουμε μία κατεύθυνση αναζήτης $p_k$
	3. Προσδιορίζουμε ένα βήμα μήκους $\alpha_k > 0$ που οδηγεί στη βελτιωμένη εκτίμηση $x_{k+1} = x_k + \alpha_k p_k$ της λύσης και επαναλαμβάνουμε το (1)
```

![[general-algo-opt.excalidraw]]

```ad-note
Η κατεύθυνση $p_k$ είναι κατεύθυνση καθόδου στα προβλήματα ελαχιστοποίησης, άρα ισχύει $f(x_k + \alpha p_k) < f(x_k)$, για $0 < \alpha \le \epsilon$
```

```ad-note
Αφού προσδιοριστεί η $p_k$, για την αναζήτηση του βήματος μήκους $\alpha_k$ λύνουμε το μονοδιάστατο πρόβλημα βελτιστοποίησης $minimize f(x_k + \alpha p_k), \alpha > 0$
```

![[searching-α-step-opt.excalidraw]]

```ad-note
Κατευθυνόμενη παράγωγος $f_u(p)$ στο σημείο $p$ ως προς την κατεύθυνση $u$: $f_u(p) = \nabla f(p) \cdot u$
```

```ad-example
Βρείτε την κατευθυνόμενη παράγωγο της συνάρτησης
$f(x_1, x_2, x_3) = x^2_1 x^2_2 + x_3(x_1 + x_2)$
στο σημείο $p = (1, -1, 2)$ ως προς την κατεύθυνση $u = \frac{1}{5}(0, 3, 4)$

**(1)** Πρώτες μερικές παράγωγοι:

- $fx_1 = 2x_1 x^2_2 + x_3$
- $fx_2 = 2x^2_1 x_2 + x_3$
- $fx_3 = x_1 + x_2$

Άρα, $\nabla f = \begin{bmatrix}2x_1 x^2_2 + x_3 & 2x^2_1 x_2 + x_3 & x_1 + x_2\end{bmatrix}$

**(2)** Κατευθυνόμενη παράγωγος:

$\nabla f(p) = \begin{bmatrix}4 & 0 & 0\end{bmatrix} \Rightarrow \nabla f(p) \cdot u = \begin{bmatrix}4 & 0 & 0\end{bmatrix} \cdot \frac{1}{5}(0, 3, 4) = 0$
```

```ad-note
Αν $\nabla f(p) \ne 0$ και $||u|| = 1$, τότε η κατευθυνόμενη παράγωγος $f_u(p)$ έχει μέγιστη τιμή ίση με $||\nabla f(p)||$ όταν $\nabla f(p)$ και $u$ είναι παράλληλα και ομόρροπα και ελάχιστη τιμή και ελάχιστη τιμή ίση με $-||\nabla f(p)||$ όταν $\nabla f(p)$ και $u$ είναι παράλληλα και αντίρροπα.
	Δηλαδή, **η κατεύθυνση του $\nabla f(p)$ είναι εκείνη του μέγιστου ρυθμού αύξησης της $f$ στο $p$ και η κατεύθυνση του $-\nabla f(p)$ είναι εκείνη του μέγιστου ρυθμού μείωσης της $f$ στο $p$**
```

```ad-example
Η θερμοκρασία των σημείων $(x_1, x_2, x_3)$ του χώρου $\mathit{R}^3$ δίνεται από τη συνάρτηση
$f(x_1, x_2, x_3) = x^2_1 - x_2 - 2x_3$
Ένα πτηνό βρίσκεται στο σημείο $p = \begin{pmatrix}1 & 2 & 1\end{pmatrix}$. Βρείτε την κατεύθυνση που πρέπει να πετάξει ώστε να ζεσταθεί περισσότερο και ταχύτερα καθώς και τον μέγιστο ρυθμό αύξησης της θερμοκρασίας

**(1)** Πρώτες μερικές παράγωγοι:

- $fx_1 = 2x_1$
- $fx_2 = -1$
- $fx_3 = -2$

Άρα $\nabla f(p) = \begin{pmatrix}2 & -1 & -2\end{pmatrix}$

**(2)** Μέγιστη τιμή

$||\nabla f(p)|| = \sqrt{2^2 + (-1)^2 + (-2)^2} = \sqrt{9} = 3$

**(3)** Κατεύθυνση

$\vec{u} = \frac{\nabla f(p)}{||\nabla f(p)} = \begin{pmatrix}\frac{2}{3} & \frac{-1}{3} & \frac{-2}{3}\end{pmatrix}$

Η διαίρεση γίνεται για κανονικοποίηση έτσι ώστε το $\vec{u}$ να είναι μοναδιαίο διάνυσμα
```

```ad-note
Ως διανύσματα καθόδου $p_k$ στην $x_{k+1} = x_k + \alpha p_k$ θεωρούμε διανύσματα τα οποία σχηματίζουν γωνία μεγαλύτερη των $90^\circ$ με το $\nabla f(x_k)$
(μικρότερη των $90^\circ$ με το $-\nabla f(x_k)$) 
```

```ad-note
Τα διανύσματα $\pm \nabla f(x_k)$ είναι κάθετα στις ισοσταθμικές (επιφάνειες για τις οποίες $f = c$) της $f$ στο σημείο $x_k$
```

![[descent-vecs-opt.excalidraw]]

```ad-note
Η κατεύθυνση $p_k$ που σχηματίζει γωνία μικρότερη από $90^\circ$ με το διάνυσμα $-\nabla f(x_k)$ ονομάζεται αποδεκτή κατεύθυνση καθόδου. Η χρήση αποδεκτής κατεύθυνσης καθόδου εξασφαλίζει ότι $f(x_{k+1}) < f(x_k)$, η οποία πρέπει να ικανοποιείται σε προβλήματα ελαχιστοποίησης
```

![[descent-direction-opt.excalidraw]]

```ad-note
Η επιλογή του βήματος $\alpha_k$ απαιτεί προσοχή, επειδή υπάρχει το ακόλουθο tradeoff: Αν το βήμα είναι πολύ μικρό, θα οδηγήσει σε ασήμαντη μείωση της συνάρτησης $f$ και, κατά συνέπεια, σε αργή σύγκλιση, ενώ αν είναι πολύ μεγάλο μπορεί να οδηγήσει τον αλγόριθμο σε αστάθεια με συνέπεια να μην οδηγηθούν οι όροι $x_k$ προς τον βελτιστοποιητή του προβλήματος.

Αν το $\alpha_k$ επιλεγεί έτσι ώστε $\alpha^k < a^{max}_k$, τότε ισχύει $f(x_k + \alpha_k p_k) < f(x_k)$
```

![[line-search-methods-opt.excalidraw|800]]

```ad-important
Μέθοδος Steepest Descent: $x_{k+1} = x_k - \alpha_k \nabla f(x_k)$

Ισχύει $p_k = -\nabla f(x_k)$, δηλαδή η κατεύθυνση αναζήτησης $p_k$ σε κάθε βήμα $k$ ισούται με την αρνητική κλίση της $f$, υπολογισμένη στο $x_k$. Η $-\nabla f(x_k)$ είναι η κατεύθυνση μέγιστης μείωσης της $f$ στην περιοχή του $x_k$

Η Steepest Descent *δεν* απαιτεί υπολογισμό δεύτερων μερικών παραγώγων, αλλά είναι ιδιαίτερα αργή (κυρίως για πολύπλοκα προβλήματα)
```

```ad-important
**Αλγόριθμος Steepst Descent**:

**(1) Αρχικοποίηση**: Επιλογή αρχικής πρόβλεψης (αρχικού διανύσματος) $x_0$ και ορισμός σταθεράς τερματισμού $\epsilon > 0$ και $k = 0$

**(2) Κύριο βήμα**:

  - Αν $||\nabla f(x_k)|| < \epsilon$ τότε ο αλγόριθμος τερματίζεται και η προσεγγιστική τιμή του βελτιστοποιητή είναι η $x_k$
  - Διαφορετικά, θέτουμε $p_k = -\nabla f(x_k)$
  - Προσδιορίζουμε ένα βήμα μήκους $\alpha_k$ που ελαχιστοποιεί τη συνάρτηση
	$\phi(\alpha_k) = f(x_k - \alpha_k \nabla f(x_k))$ ως προς $\alpha_k > 0$
  - Προσδιορίζουμε τη βελτιωμένη εκτίμηση της λύσης του προβλήματος
    $x_{k+1} = x_k - \alpha_k \nabla f(x_k)$
  - Επαναλαμβάνουμε το κύριο βήμα για το $k + 1$
```

![[steepest-descent.excalidraw|800]]

```ad-note
$\forall k \in \mathit{N}$ το διάνυσμα που ενώνει τα $x_k$ και $x_{k+1}$ είναι κάθετο στο διάνυσμα που ενώνει τα $x_{k+1}$ και $x_{k+2}$
```

![[steepest-descent-vertical-opt.excalidraw|800]]

```ad-example
TODO
```

